{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 5. Penalizaciones L1 y L2\n",
        "Sin el uso de librerías, programe las penalizaciones L1 y L2, aplicando normalización.\n"
      ],
      "metadata": {
        "id": "v_lWVWTBlnkm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Preparación del Entorno\n",
        "Primero, montamos Google Drive y cargamos el dataset:"
      ],
      "metadata": {
        "id": "_Z3j6r9JAZTl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "# Montar Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Cargar el archivo CSV\n",
        "df = pd.read_csv('/content/drive/My Drive/TAREAS U/8vo semestre/IA/Apoyo 1er parcial/4final.csv', delimiter=',')\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaJlFktoAbiF",
        "outputId": "9c518fe7-b582-4ab7-b787-fea63f2d78bf"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "   Rank        Date  Danceability    Energy  Loudness  Speechiness  \\\n",
            "0     1  2023-05-29     -0.060460  0.681445 -0.029892    -0.670052   \n",
            "1     1  2023-05-29     -0.060460  0.681445 -0.029892    -0.670052   \n",
            "2     2  2023-05-29     -0.181634  0.963016  0.377901    -0.364715   \n",
            "3     3  2023-05-29      1.030105 -1.188990 -0.206826     2.601422   \n",
            "4     3  2023-05-29      1.030105 -1.188990 -0.206826     2.601422   \n",
            "\n",
            "   Acousticness  Instrumentalness   Valence  Points (Total)  ...  \\\n",
            "0      1.047175         -0.171931  1.333454        1.654353  ...   \n",
            "1      1.047175         -0.171931  1.333454        1.654353  ...   \n",
            "2     -0.414239          7.023328 -1.240858        1.637321  ...   \n",
            "3     -0.113359         -0.171931  0.153561        1.620290  ...   \n",
            "4     -0.113359         -0.171931  0.153561        1.620290  ...   \n",
            "\n",
            "   Nationality_Unknown  Continent_Africa  Continent_Anglo-America  \\\n",
            "0                  0.0               0.0                      0.0   \n",
            "1                  0.0               0.0                      0.0   \n",
            "2                  0.0               0.0                      0.0   \n",
            "3                  0.0               0.0                      0.0   \n",
            "4                  0.0               0.0                      0.0   \n",
            "\n",
            "   Continent_Asia  Continent_Europe  Continent_Latin-America  \\\n",
            "0             0.0               0.0                      1.0   \n",
            "1             0.0               0.0                      1.0   \n",
            "2             0.0               0.0                      1.0   \n",
            "3             0.0               0.0                      1.0   \n",
            "4             0.0               0.0                      1.0   \n",
            "\n",
            "   Continent_Oceania  Continent_Unknown  Danceability_binned  Energy_binned  \n",
            "0                0.0                0.0                    3              3  \n",
            "1                0.0                0.0                    3              3  \n",
            "2                0.0                0.0                    3              3  \n",
            "3                0.0                0.0                    4              2  \n",
            "4                0.0                0.0                    4              2  \n",
            "\n",
            "[5 rows x 394 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Dividir los Datos\n",
        "A continuación, separamos las características relevantes y la variable objetivo. Usaremos Points (Total) como variable objetivo tanto para regresión como para clasificación:"
      ],
      "metadata": {
        "id": "KsDrf24lAdT0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Selecciona las características relevantes\n",
        "features = ['Danceability', 'Energy', 'Loudness', 'Speechiness', 'Acousticness', 'Instrumentalness', 'Valence']\n",
        "X = df[features]\n",
        "\n",
        "# Variable objetivo para regresión\n",
        "y_regression = df['Points (Total)']\n",
        "\n",
        "# Variable objetivo para clasificación\n",
        "threshold = df['Points (Total)'].median()\n",
        "df['Success'] = (df['Points (Total)'] > threshold).astype(int)\n",
        "y_classification = df['Success']\n",
        "\n",
        "# Dividir los datos\n",
        "X_train, X_test, y_train_reg, y_test_reg = train_test_split(X, y_regression, test_size=0.2, random_state=42)\n",
        "X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(X, y_classification, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "Kf7LYahhAdAz"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Evaluación de Modelos\n",
        "Probamos varios modelos de regresión y clasificación. Evaluamos su desempeño utilizando métricas adecuadas."
      ],
      "metadata": {
        "id": "Qdrhrhf6AkTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression, Lasso, Ridge, LogisticRegression\n",
        "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingRegressor, GradientBoostingClassifier\n",
        "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, classification_report\n",
        "\n",
        "# Lista de modelos para regresión\n",
        "regression_models = {\n",
        "    \"Regresión Lineal\": LinearRegression(),\n",
        "    \"Regresión Lasso\": Lasso(),\n",
        "    \"Regresión Ridge\": Ridge(),\n",
        "    \"Árbol de Decisión\": DecisionTreeRegressor(),\n",
        "    \"Random Forest\": RandomForestRegressor(),\n",
        "    \"Gradient Boosting\": GradientBoostingRegressor()\n",
        "}\n",
        "\n",
        "# Evaluar modelos de regresión\n",
        "for name, model in regression_models.items():\n",
        "    model.fit(X_train, y_train_reg)\n",
        "    y_pred = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test_reg, y_pred)\n",
        "    r2 = r2_score(y_test_reg, y_pred)\n",
        "    print(f\"{name} - MSE: {mse}, R^2: {r2}\")\n",
        "\n",
        "# Lista de modelos para clasificación\n",
        "classification_models = {\n",
        "    \"Regresión Logística\": LogisticRegression(max_iter=1000),\n",
        "    \"Árbol de Decisión\": DecisionTreeClassifier(),\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier()\n",
        "}\n",
        "\n",
        "# Evaluar modelos de clasificación\n",
        "for name, model in classification_models.items():\n",
        "    model.fit(X_train_class, y_train_class)\n",
        "    y_pred_class = model.predict(X_test_class)\n",
        "    accuracy = accuracy_score(y_test_class, y_pred_class)\n",
        "    report = classification_report(y_test_class, y_pred_class)\n",
        "    print(f\"{name} - Accuracy: {accuracy}\")\n",
        "    print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wGF3StqAnhj",
        "outputId": "65960474-e2ef-4e97-d9ac-8100db9b0b8d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regresión Lineal - MSE: 0.9816917305547017, R^2: 0.004105394544546281\n",
            "Regresión Lasso - MSE: 0.9859535483272904, R^2: -0.0002180821610759942\n",
            "Regresión Ridge - MSE: 0.981691659243298, R^2: 0.004105466887665776\n",
            "Árbol de Decisión - MSE: 0.18122439545782154, R^2: 0.8161536944888081\n",
            "Random Forest - MSE: 0.17939147010546327, R^2: 0.8180131381550848\n",
            "Gradient Boosting - MSE: 0.4061026655488337, R^2: 0.5880219408055531\n",
            "Regresión Logística - Accuracy: 0.5186543023506578\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.56      0.54      2324\n",
            "           1       0.52      0.47      0.50      2313\n",
            "\n",
            "    accuracy                           0.52      4637\n",
            "   macro avg       0.52      0.52      0.52      4637\n",
            "weighted avg       0.52      0.52      0.52      4637\n",
            "\n",
            "Árbol de Decisión - Accuracy: 0.8768600388182014\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.90      0.88      2324\n",
            "           1       0.89      0.86      0.87      2313\n",
            "\n",
            "    accuracy                           0.88      4637\n",
            "   macro avg       0.88      0.88      0.88      4637\n",
            "weighted avg       0.88      0.88      0.88      4637\n",
            "\n",
            "Random Forest - Accuracy: 0.8766443821436274\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.90      0.88      2324\n",
            "           1       0.89      0.86      0.87      2313\n",
            "\n",
            "    accuracy                           0.88      4637\n",
            "   macro avg       0.88      0.88      0.88      4637\n",
            "weighted avg       0.88      0.88      0.88      4637\n",
            "\n",
            "Gradient Boosting - Accuracy: 0.8404140608151822\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.81      0.84      2324\n",
            "           1       0.82      0.87      0.84      2313\n",
            "\n",
            "    accuracy                           0.84      4637\n",
            "   macro avg       0.84      0.84      0.84      4637\n",
            "weighted avg       0.84      0.84      0.84      4637\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Comparación de Modelos\n",
        "\n",
        "Después de evaluar los modelos, observamos que:\n",
        "\n",
        "**Métricas de Regresión:**\n",
        "- **Árbol de Decisión:** MSE: 0.181, R²: 0.816\n",
        "- **Random Forest:** MSE: 0.179, R²: 0.818\n",
        "\n",
        "**Métricas de Clasificación:**\n",
        "- **Árbol de Decisión:** Accuracy: 0.8766\n",
        "- **Random Forest:** Accuracy: 0.8782\n",
        "\n",
        "Dado que Random Forest supera al Árbol de Decisión en ambas métricas, se elige Random Forest como el modelo preferido.\n"
      ],
      "metadata": {
        "id": "AH8C62oFApss"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Selección del Mejor Lambda para Penalización\n",
        "Para ajustar la penalización L1 (Lasso) y L2 (Ridge), normalizamos los datos y probamos diferentes valores de lambda."
      ],
      "metadata": {
        "id": "cM91C9LvAvgi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalización\n",
        "X_mean = np.mean(X.values, axis=0)\n",
        "X_std = np.std(X.values, axis=0)\n",
        "X_normalized = (X - X_mean) / X_std\n",
        "\n",
        "# Inicializar coeficientes\n",
        "coef = np.zeros(X_normalized.shape[1])\n",
        "\n",
        "# Parámetros\n",
        "learning_rate = 0.01\n",
        "iterations = 1000\n",
        "lambdas = np.logspace(-3, 3, 7)  # Desde 0.001 hasta 1000\n",
        "\n",
        "# Resultados\n",
        "lasso_results = []\n",
        "ridge_results = []\n",
        "\n",
        "# Bucle para evaluar Lasso\n",
        "for alpha in lambdas:\n",
        "    lasso_model = Lasso(alpha=alpha)\n",
        "    lasso_model.fit(X_normalized, y_regression)\n",
        "    lasso_pred = lasso_model.predict(X_normalized)\n",
        "    lasso_mse = mean_squared_error(y_regression, lasso_pred)\n",
        "    lasso_results.append((alpha, lasso_mse))\n",
        "\n",
        "# Bucle para evaluar Ridge\n",
        "for alpha in lambdas:\n",
        "    ridge_model = Ridge(alpha=alpha)\n",
        "    ridge_model.fit(X_normalized, y_regression)\n",
        "    ridge_pred = ridge_model.predict(X_normalized)\n",
        "    ridge_mse = mean_squared_error(y_regression, ridge_pred)\n",
        "    ridge_results.append((alpha, ridge_mse))\n",
        "\n",
        "# Imprimir resultados\n",
        "print(\"Lasso Results:\")\n",
        "for alpha, mse in lasso_results:\n",
        "    print(f\"Lambda: {alpha:.3f}, MSE: {mse:.3f}\")\n",
        "\n",
        "print(\"\\nRidge Results:\")\n",
        "for alpha, mse in ridge_results:\n",
        "    print(f\"Lambda: {alpha:.3f}, MSE: {mse:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIj9xUUhAtDT",
        "outputId": "970fc890-3487-436b-ee84-f5c4b0487ac4"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lasso Results:\n",
            "Lambda: 0.001, MSE: 0.994\n",
            "Lambda: 0.010, MSE: 0.995\n",
            "Lambda: 0.100, MSE: 1.000\n",
            "Lambda: 1.000, MSE: 1.000\n",
            "Lambda: 10.000, MSE: 1.000\n",
            "Lambda: 100.000, MSE: 1.000\n",
            "Lambda: 1000.000, MSE: 1.000\n",
            "\n",
            "Ridge Results:\n",
            "Lambda: 0.001, MSE: 0.994\n",
            "Lambda: 0.010, MSE: 0.994\n",
            "Lambda: 0.100, MSE: 0.994\n",
            "Lambda: 1.000, MSE: 0.994\n",
            "Lambda: 10.000, MSE: 0.994\n",
            "Lambda: 100.000, MSE: 0.994\n",
            "Lambda: 1000.000, MSE: 0.994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Conclusión\n",
        "Analizando los resultados de la penalización, encontramos que:\n",
        "\n",
        "Ridge mantiene un MSE más estable en comparación con Lasso.\n",
        "Se recomienda usar Ridge con\n",
        "𝜆\n",
        "=\n",
        "0.001\n",
        "λ=0.001 o\n",
        "𝜆\n",
        "=\n",
        "0.010\n",
        "λ=0.010 para un buen balance entre regularización y precisión."
      ],
      "metadata": {
        "id": "VRSnzIrpA0Uz"
      }
    }
  ]
}